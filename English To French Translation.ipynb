{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled15.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2H3rw5Jh6BIu"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# English to French prediction using encoder-decoder model."
      ],
      "metadata": {
        "id": "V_97lbf8YfIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wWlHi29nYp0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## import the needed libraries"
      ],
      "metadata": {
        "id": "YvEnFgfGYhzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "zmr7EHl279_G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## initialize the variables to use in our model\n",
        "batch_size = 64  \n",
        "epochs = 100  \n",
        "latent_dim = 256  \n",
        "num_samples = 10000"
      ],
      "metadata": {
        "id": "CR4hKuKO8DKA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## mount the drive to google colab\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "STWejZrU8Ppr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9bUT1mD8SoQ",
        "outputId": "ea453cfd-bee3-4474-ee77-b5be2d587d2c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## extracted the zip file from colab\n",
        "from zipfile import ZipFile"
      ],
      "metadata": {
        "id": "YeDdPP3W8UkH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with ZipFile('/content/drive/MyDrive/fra-eng.zip','r') as zipobj:\n",
        "   zipobj.extractall('/content/drive/MyDrive/frenchtoenglish')"
      ],
      "metadata": {
        "id": "Bm3P0Bpv8ZGA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/frenchtoenglish/fra.txt'"
      ],
      "metadata": {
        "id": "DbnTA-DV8b5o"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## open the text file\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')"
      ],
      "metadata": {
        "id": "649onQbY8eUZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-4uSZBU8jn4",
        "outputId": "be1c3722-c443-4388-9d13-d6c95e3696b3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "194514"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## put each english word in a line to input_texts\n",
        "## put each french word in a line to target_texts\n",
        "## put each characters in english to input_characters\n",
        "## put each characters in french to target_characters\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split('\\t')\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)"
      ],
      "metadata": {
        "id": "BeHiopWV8mJQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
      ],
      "metadata": {
        "id": "Ej6y5hlk9Z9Q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## create a dictionary out of input_characters and target_characters\n",
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)])"
      ],
      "metadata": {
        "id": "hpo872TP9gM4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## one hot encode your all elements of input_texts and target_texts\n",
        "encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens),dtype='float32')\n",
        "decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens),dtype='float32')\n",
        "decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens),dtype='float32')"
      ],
      "metadata": {
        "id": "tqT601vn-M1x"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## now use the above created np arrays and represesnt all ur datas in a one hot encoded form.\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
        "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
      ],
      "metadata": {
        "id": "waKNNKEo-iP8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## create the encoder model\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]"
      ],
      "metadata": {
        "id": "aNGdR9yb-w5Z"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the decoder\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,   initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "metadata": {
        "id": "1xSH1rhE_EER"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "metadata": {
        "id": "2RLaFGL3_MU0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## train the created model with the encoded datas\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)"
      ],
      "metadata": {
        "id": "F0ivOYOa_TpA",
        "outputId": "8675487b-f219-4369-a5ff-85c75800f4b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "125/125 [==============================] - 58s 415ms/step - loss: 1.1291 - accuracy: 0.7372 - val_loss: 1.0235 - val_accuracy: 0.7264\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 52s 412ms/step - loss: 0.8075 - accuracy: 0.7821 - val_loss: 0.8098 - val_accuracy: 0.7776\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 52s 414ms/step - loss: 0.6545 - accuracy: 0.8162 - val_loss: 0.6991 - val_accuracy: 0.7960\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 50s 401ms/step - loss: 0.5733 - accuracy: 0.8331 - val_loss: 0.6311 - val_accuracy: 0.8159\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 52s 414ms/step - loss: 0.5248 - accuracy: 0.8467 - val_loss: 0.5816 - val_accuracy: 0.8334\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 50s 401ms/step - loss: 0.4892 - accuracy: 0.8563 - val_loss: 0.5709 - val_accuracy: 0.8329\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 50s 402ms/step - loss: 0.4619 - accuracy: 0.8633 - val_loss: 0.5346 - val_accuracy: 0.8434\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 52s 417ms/step - loss: 0.4397 - accuracy: 0.8693 - val_loss: 0.5174 - val_accuracy: 0.8478\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 50s 402ms/step - loss: 0.4203 - accuracy: 0.8749 - val_loss: 0.5035 - val_accuracy: 0.8518\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 50s 403ms/step - loss: 0.4024 - accuracy: 0.8797 - val_loss: 0.4914 - val_accuracy: 0.8550\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 52s 419ms/step - loss: 0.3859 - accuracy: 0.8846 - val_loss: 0.4801 - val_accuracy: 0.8588\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 50s 401ms/step - loss: 0.3705 - accuracy: 0.8886 - val_loss: 0.4701 - val_accuracy: 0.8619\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 50s 401ms/step - loss: 0.3561 - accuracy: 0.8929 - val_loss: 0.4663 - val_accuracy: 0.8629\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 52s 415ms/step - loss: 0.3422 - accuracy: 0.8972 - val_loss: 0.4568 - val_accuracy: 0.8664\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 50s 403ms/step - loss: 0.3293 - accuracy: 0.9007 - val_loss: 0.4512 - val_accuracy: 0.8684\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 52s 414ms/step - loss: 0.3174 - accuracy: 0.9043 - val_loss: 0.4467 - val_accuracy: 0.8704\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 51s 405ms/step - loss: 0.3059 - accuracy: 0.9078 - val_loss: 0.4419 - val_accuracy: 0.8715\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 51s 405ms/step - loss: 0.2944 - accuracy: 0.9112 - val_loss: 0.4460 - val_accuracy: 0.8709\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 52s 419ms/step - loss: 0.2840 - accuracy: 0.9143 - val_loss: 0.4449 - val_accuracy: 0.8724\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 51s 406ms/step - loss: 0.2736 - accuracy: 0.9176 - val_loss: 0.4410 - val_accuracy: 0.8737\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 51s 406ms/step - loss: 0.2640 - accuracy: 0.9204 - val_loss: 0.4416 - val_accuracy: 0.8743\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 53s 427ms/step - loss: 0.2549 - accuracy: 0.9228 - val_loss: 0.4437 - val_accuracy: 0.8746\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 51s 405ms/step - loss: 0.2461 - accuracy: 0.9257 - val_loss: 0.4460 - val_accuracy: 0.8742\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 50s 401ms/step - loss: 0.2376 - accuracy: 0.9282 - val_loss: 0.4445 - val_accuracy: 0.8753\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 52s 414ms/step - loss: 0.2302 - accuracy: 0.9302 - val_loss: 0.4451 - val_accuracy: 0.8757\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 50s 404ms/step - loss: 0.2222 - accuracy: 0.9327 - val_loss: 0.4450 - val_accuracy: 0.8765\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 52s 415ms/step - loss: 0.2147 - accuracy: 0.9347 - val_loss: 0.4529 - val_accuracy: 0.8758\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 50s 401ms/step - loss: 0.2079 - accuracy: 0.9369 - val_loss: 0.4538 - val_accuracy: 0.8772\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 51s 406ms/step - loss: 0.2009 - accuracy: 0.9389 - val_loss: 0.4583 - val_accuracy: 0.8759\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 52s 417ms/step - loss: 0.1948 - accuracy: 0.9408 - val_loss: 0.4620 - val_accuracy: 0.8763\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 50s 403ms/step - loss: 0.1886 - accuracy: 0.9426 - val_loss: 0.4668 - val_accuracy: 0.8766\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 51s 404ms/step - loss: 0.1829 - accuracy: 0.9441 - val_loss: 0.4714 - val_accuracy: 0.8761\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 52s 417ms/step - loss: 0.1772 - accuracy: 0.9459 - val_loss: 0.4747 - val_accuracy: 0.8759\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 50s 403ms/step - loss: 0.1721 - accuracy: 0.9475 - val_loss: 0.4707 - val_accuracy: 0.8759\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 51s 407ms/step - loss: 0.1669 - accuracy: 0.9490 - val_loss: 0.4821 - val_accuracy: 0.8761\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 52s 419ms/step - loss: 0.1621 - accuracy: 0.9503 - val_loss: 0.4915 - val_accuracy: 0.8753\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 51s 405ms/step - loss: 0.1575 - accuracy: 0.9518 - val_loss: 0.4934 - val_accuracy: 0.8749\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 56s 447ms/step - loss: 0.1530 - accuracy: 0.9531 - val_loss: 0.4993 - val_accuracy: 0.8759\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 54s 433ms/step - loss: 0.1484 - accuracy: 0.9545 - val_loss: 0.5011 - val_accuracy: 0.8751\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 51s 411ms/step - loss: 0.1440 - accuracy: 0.9558 - val_loss: 0.5068 - val_accuracy: 0.8755\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 55s 440ms/step - loss: 0.1401 - accuracy: 0.9570 - val_loss: 0.5082 - val_accuracy: 0.8759\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 52s 413ms/step - loss: 0.1366 - accuracy: 0.9579 - val_loss: 0.5161 - val_accuracy: 0.8745\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 55s 442ms/step - loss: 0.1328 - accuracy: 0.9589 - val_loss: 0.5259 - val_accuracy: 0.8741\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 52s 418ms/step - loss: 0.1290 - accuracy: 0.9602 - val_loss: 0.5269 - val_accuracy: 0.8734\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 56s 452ms/step - loss: 0.1260 - accuracy: 0.9611 - val_loss: 0.5321 - val_accuracy: 0.8741\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 54s 431ms/step - loss: 0.1229 - accuracy: 0.9619 - val_loss: 0.5364 - val_accuracy: 0.8743\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 51s 409ms/step - loss: 0.1196 - accuracy: 0.9631 - val_loss: 0.5390 - val_accuracy: 0.8743\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 50s 402ms/step - loss: 0.1165 - accuracy: 0.9638 - val_loss: 0.5514 - val_accuracy: 0.8735\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 52s 417ms/step - loss: 0.1136 - accuracy: 0.9646 - val_loss: 0.5573 - val_accuracy: 0.8738\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 50s 404ms/step - loss: 0.1107 - accuracy: 0.9652 - val_loss: 0.5612 - val_accuracy: 0.8743\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 52s 418ms/step - loss: 0.1083 - accuracy: 0.9661 - val_loss: 0.5605 - val_accuracy: 0.8737\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 51s 405ms/step - loss: 0.1054 - accuracy: 0.9671 - val_loss: 0.5708 - val_accuracy: 0.8729\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 51s 407ms/step - loss: 0.1031 - accuracy: 0.9674 - val_loss: 0.5720 - val_accuracy: 0.8734\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 52s 419ms/step - loss: 0.1006 - accuracy: 0.9685 - val_loss: 0.5821 - val_accuracy: 0.8725\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 51s 406ms/step - loss: 0.0983 - accuracy: 0.9689 - val_loss: 0.5879 - val_accuracy: 0.8723\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 51s 407ms/step - loss: 0.0960 - accuracy: 0.9698 - val_loss: 0.5902 - val_accuracy: 0.8728\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 52s 416ms/step - loss: 0.0934 - accuracy: 0.9705 - val_loss: 0.5948 - val_accuracy: 0.8731\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 50s 404ms/step - loss: 0.0915 - accuracy: 0.9711 - val_loss: 0.5988 - val_accuracy: 0.8727\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 52s 415ms/step - loss: 0.0899 - accuracy: 0.9713 - val_loss: 0.6086 - val_accuracy: 0.8716\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 50s 402ms/step - loss: 0.0879 - accuracy: 0.9719 - val_loss: 0.6070 - val_accuracy: 0.8727\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 51s 408ms/step - loss: 0.0855 - accuracy: 0.9728 - val_loss: 0.6150 - val_accuracy: 0.8719\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 55s 440ms/step - loss: 0.0839 - accuracy: 0.9732 - val_loss: 0.6215 - val_accuracy: 0.8713\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 51s 405ms/step - loss: 0.0822 - accuracy: 0.9734 - val_loss: 0.6259 - val_accuracy: 0.8717\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 51s 407ms/step - loss: 0.0806 - accuracy: 0.9740 - val_loss: 0.6297 - val_accuracy: 0.8713\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 52s 416ms/step - loss: 0.0791 - accuracy: 0.9745 - val_loss: 0.6304 - val_accuracy: 0.8721\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 51s 404ms/step - loss: 0.0773 - accuracy: 0.9748 - val_loss: 0.6387 - val_accuracy: 0.8714\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 52s 417ms/step - loss: 0.0760 - accuracy: 0.9753 - val_loss: 0.6476 - val_accuracy: 0.8727\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 51s 406ms/step - loss: 0.0742 - accuracy: 0.9758 - val_loss: 0.6545 - val_accuracy: 0.8709\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 52s 413ms/step - loss: 0.0730 - accuracy: 0.9762 - val_loss: 0.6454 - val_accuracy: 0.8717\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 56s 450ms/step - loss: 0.0714 - accuracy: 0.9765 - val_loss: 0.6567 - val_accuracy: 0.8713\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 51s 409ms/step - loss: 0.0700 - accuracy: 0.9769 - val_loss: 0.6582 - val_accuracy: 0.8718\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 52s 420ms/step - loss: 0.0687 - accuracy: 0.9775 - val_loss: 0.6638 - val_accuracy: 0.8722\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 51s 408ms/step - loss: 0.0676 - accuracy: 0.9778 - val_loss: 0.6716 - val_accuracy: 0.8706\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 51s 408ms/step - loss: 0.0662 - accuracy: 0.9781 - val_loss: 0.6770 - val_accuracy: 0.8704\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 53s 423ms/step - loss: 0.0650 - accuracy: 0.9783 - val_loss: 0.6743 - val_accuracy: 0.8721\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 51s 409ms/step - loss: 0.0639 - accuracy: 0.9786 - val_loss: 0.6868 - val_accuracy: 0.8711\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 51s 407ms/step - loss: 0.0630 - accuracy: 0.9787 - val_loss: 0.6802 - val_accuracy: 0.8719\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 54s 434ms/step - loss: 0.0617 - accuracy: 0.9793 - val_loss: 0.6881 - val_accuracy: 0.8712\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 51s 408ms/step - loss: 0.0610 - accuracy: 0.9797 - val_loss: 0.6918 - val_accuracy: 0.8710\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 53s 426ms/step - loss: 0.0599 - accuracy: 0.9796 - val_loss: 0.6917 - val_accuracy: 0.8709\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 51s 412ms/step - loss: 0.0586 - accuracy: 0.9801 - val_loss: 0.6983 - val_accuracy: 0.8713\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 51s 407ms/step - loss: 0.0580 - accuracy: 0.9803 - val_loss: 0.6970 - val_accuracy: 0.8714\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 53s 421ms/step - loss: 0.0569 - accuracy: 0.9805 - val_loss: 0.7092 - val_accuracy: 0.8696\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 51s 410ms/step - loss: 0.0562 - accuracy: 0.9809 - val_loss: 0.7036 - val_accuracy: 0.8710\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 53s 421ms/step - loss: 0.0552 - accuracy: 0.9810 - val_loss: 0.7139 - val_accuracy: 0.8707\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 51s 407ms/step - loss: 0.0541 - accuracy: 0.9812 - val_loss: 0.7175 - val_accuracy: 0.8705\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 51s 409ms/step - loss: 0.0537 - accuracy: 0.9815 - val_loss: 0.7255 - val_accuracy: 0.8704\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 52s 418ms/step - loss: 0.0530 - accuracy: 0.9817 - val_loss: 0.7227 - val_accuracy: 0.8707\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 50s 403ms/step - loss: 0.0521 - accuracy: 0.9818 - val_loss: 0.7268 - val_accuracy: 0.8712\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 51s 406ms/step - loss: 0.0514 - accuracy: 0.9821 - val_loss: 0.7324 - val_accuracy: 0.8713\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 52s 418ms/step - loss: 0.0504 - accuracy: 0.9823 - val_loss: 0.7412 - val_accuracy: 0.8700\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 50s 403ms/step - loss: 0.0499 - accuracy: 0.9823 - val_loss: 0.7309 - val_accuracy: 0.8707\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 52s 417ms/step - loss: 0.0495 - accuracy: 0.9826 - val_loss: 0.7372 - val_accuracy: 0.8706\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 50s 402ms/step - loss: 0.0485 - accuracy: 0.9827 - val_loss: 0.7401 - val_accuracy: 0.8701\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 50s 404ms/step - loss: 0.0480 - accuracy: 0.9830 - val_loss: 0.7430 - val_accuracy: 0.8711\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 52s 417ms/step - loss: 0.0473 - accuracy: 0.9834 - val_loss: 0.7472 - val_accuracy: 0.8703\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 51s 405ms/step - loss: 0.0472 - accuracy: 0.9830 - val_loss: 0.7492 - val_accuracy: 0.8702\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 52s 418ms/step - loss: 0.0463 - accuracy: 0.9835 - val_loss: 0.7494 - val_accuracy: 0.8709\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 51s 406ms/step - loss: 0.0455 - accuracy: 0.9838 - val_loss: 0.7573 - val_accuracy: 0.8714\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 51s 405ms/step - loss: 0.0454 - accuracy: 0.9837 - val_loss: 0.7570 - val_accuracy: 0.8704\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fab1b4f8e50>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## take encoder\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n"
      ],
      "metadata": {
        "id": "PQq5YGDC_bdQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## take decoder\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)"
      ],
      "metadata": {
        "id": "uUkitM4o76vh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())"
      ],
      "metadata": {
        "id": "pSENZc89G2fN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## function used to predict the french equivalent of english sentence passed in one hot encoded form.\n",
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "U_wYnb8kG4g8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## make predictions on first 100 english words and print\n",
        "## its predicted french equivalent.\n",
        "for seq_index in range(100):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "metadata": {
        "id": "UsORQS0GG6q1",
        "outputId": "cba6ed17-6ad4-480b-ca66-e55fbefcbe9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Bouge !\n",
            "\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Bouge !\n",
            "\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Bouge !\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Salut !\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Salut !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Who?\n",
            "Decoded sentence: Qui ?\n",
            "\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Waouh !\n",
            "\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Waouh !\n",
            "\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Waouh !\n",
            "\n",
            "-\n",
            "Input sentence: Duck!\n",
            "Decoded sentence: Baissez-vous !\n",
            "\n",
            "-\n",
            "Input sentence: Duck!\n",
            "Decoded sentence: Baissez-vous !\n",
            "\n",
            "-\n",
            "Input sentence: Duck!\n",
            "Decoded sentence: Baissez-vous !\n",
            "\n",
            "-\n",
            "Input sentence: Fire!\n",
            "Decoded sentence: Au feu !\n",
            "\n",
            "-\n",
            "Input sentence: Help!\n",
            "Decoded sentence: À l'aide !\n",
            "\n",
            "-\n",
            "Input sentence: Hide.\n",
            "Decoded sentence: Cache-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Hide.\n",
            "Decoded sentence: Cache-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Jump!\n",
            "Decoded sentence: Saute.\n",
            "\n",
            "-\n",
            "Input sentence: Jump.\n",
            "Decoded sentence: Saute.\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Arrête-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Arrête-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Arrête-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: Attends !\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: Attends !\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: Attends !\n",
            "\n",
            "-\n",
            "Input sentence: Wait.\n",
            "Decoded sentence: Attends !\n",
            "\n",
            "-\n",
            "Input sentence: Wait.\n",
            "Decoded sentence: Attends !\n",
            "\n",
            "-\n",
            "Input sentence: Wait.\n",
            "Decoded sentence: Attends !\n",
            "\n",
            "-\n",
            "Input sentence: Wait.\n",
            "Decoded sentence: Attends !\n",
            "\n",
            "-\n",
            "Input sentence: Begin.\n",
            "Decoded sentence: Commence.\n",
            "\n",
            "-\n",
            "Input sentence: Begin.\n",
            "Decoded sentence: Commence.\n",
            "\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: Poursuis.\n",
            "\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: Poursuis.\n",
            "\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: Poursuis.\n",
            "\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: Salut !\n",
            "\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: Salut !\n",
            "\n",
            "-\n",
            "Input sentence: I see.\n",
            "Decoded sentence: Je comprends.\n",
            "\n",
            "-\n",
            "Input sentence: I see.\n",
            "Decoded sentence: Je comprends.\n",
            "\n",
            "-\n",
            "Input sentence: I try.\n",
            "Decoded sentence: J'essaye.\n",
            "\n",
            "-\n",
            "Input sentence: I won!\n",
            "Decoded sentence: J'ai gagné !\n",
            "\n",
            "-\n",
            "Input sentence: I won!\n",
            "Decoded sentence: J'ai gagné !\n",
            "\n",
            "-\n",
            "Input sentence: I won.\n",
            "Decoded sentence: J’ai gagné.\n",
            "\n",
            "-\n",
            "Input sentence: Oh no!\n",
            "Decoded sentence: Oh non !\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Souris pour la caméra.\n",
            "\n",
            "-\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Souris pour la caméra.\n",
            "\n",
            "-\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Souris pour la caméra.\n",
            "\n",
            "-\n",
            "Input sentence: Sorry?\n",
            "Decoded sentence: Pardon ?\n",
            "\n",
            "-\n",
            "Input sentence: Attack!\n",
            "Decoded sentence: Attaque !\n",
            "\n",
            "-\n",
            "Input sentence: Attack!\n",
            "Decoded sentence: Attaque !\n",
            "\n",
            "-\n",
            "Input sentence: Attack!\n",
            "Decoded sentence: Attaque !\n",
            "\n",
            "-\n",
            "Input sentence: Buy it.\n",
            "Decoded sentence: Achetez-le !\n",
            "\n",
            "-\n",
            "Input sentence: Buy it.\n",
            "Decoded sentence: Achetez-le !\n",
            "\n",
            "-\n",
            "Input sentence: Buy it.\n",
            "Decoded sentence: Achetez-le !\n",
            "\n",
            "-\n",
            "Input sentence: Buy it.\n",
            "Decoded sentence: Achetez-le !\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Santé !\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Santé !\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Santé !\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Santé !\n",
            "\n",
            "-\n",
            "Input sentence: Eat it.\n",
            "Decoded sentence: Mangez-le.\n",
            "\n",
            "-\n",
            "Input sentence: Eat it.\n",
            "Decoded sentence: Mangez-le.\n",
            "\n",
            "-\n",
            "Input sentence: Get up.\n",
            "Decoded sentence: Lève-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Get up.\n",
            "Decoded sentence: Lève-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Get up.\n",
            "Decoded sentence: Lève-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Vas-y maintenant.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Vas-y maintenant.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Vas-y maintenant.\n",
            "\n",
            "-\n",
            "Input sentence: Got it!\n",
            "Decoded sentence: Compris !\n",
            "\n",
            "-\n",
            "Input sentence: Got it!\n",
            "Decoded sentence: Compris !\n",
            "\n",
            "-\n",
            "Input sentence: Got it!\n",
            "Decoded sentence: Compris !\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: T'as capté ?\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: T'as capté ?\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: T'as capté ?\n",
            "\n",
            "-\n",
            "Input sentence: Hop in.\n",
            "Decoded sentence: Montez.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BBSAs7awNCU6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fyRi-HrGG8fP"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2FJwo39TIH66"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xD3r_i4EIInN"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Df7Bw38cIR3u"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hmQE__U5Tu1S"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ApCaSLtbTyNF"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}